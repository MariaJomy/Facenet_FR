{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloning the facenet pytorch model from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ! git clone https://github.com/timesler/facenet-pytorch.git facenet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "# Define MTCNN module\n",
    "\n",
    "# Note that, since MTCNN is a collection of neural nets and other code, the\n",
    "# device must be passed in the following way to enable copying of objects when\n",
    "# needed internally.\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, prewhiten=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def cos(a,b):\n",
    "    minx = -1 \n",
    "    maxx = 1\n",
    "    return (cos_sim(a,b)- minx)/(maxx-minx)\n",
    "\n",
    "\n",
    "\n",
    "# Define Inception Resnet V1 module\n",
    "\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Define a dataset and data loader\n",
    "dataset = datasets.ImageFolder('data/china')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=lambda x: x[0])\n",
    "\n",
    "# Perfom MTCNN facial detection\n",
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        print('Face detected with probability: {:8f}'.format(prob))\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])\n",
    "\n",
    "# Calculate image embeddings\n",
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).cpu()\n",
    "\n",
    "\n",
    "\n",
    "# Print distance matrix for classes\n",
    "\n",
    "cos_sim = nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "for i in range(0,len(names)):\n",
    "    emb=embeddings[i].unsqueeze(0) \n",
    "    dist =cos(embeddings[0],emb)\n",
    "    \n",
    "    \n",
    "dists = [[cos(e1,e2).item() for e2 in embeddings] for e1 in embeddings]\n",
    "print(pd.DataFrame(dists, columns=names, index=names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1,extract_face\n",
    "from PIL import Image,ImageDraw\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def cos(a,b):\n",
    "    minx = -1 \n",
    "    maxx = 1\n",
    "    return (cos_sim(a,b)- minx)/(maxx-minx)\n",
    "\n",
    "\n",
    "\n",
    "def verify(embedding):\n",
    "    \n",
    "    for i,k in enumerate(embeddings):\n",
    "        for j,l in enumerate(embedding):\n",
    "            dist =cos(k,l)\n",
    "    \n",
    "            \n",
    "    # Chosen threshold is 0.85  \n",
    "            if dist > 0.85:\n",
    "                text=names[i]\n",
    "                \n",
    "                cv2.putText(im, text,(boxes[j][0].astype(int),boxes[j][3].astype(int)), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,255,0), 2)\n",
    "                print(text)\n",
    "            \n",
    "device = torch.device('cpu')        \n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to('cpu')\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, prewhiten=True,\n",
    "    device=device,keep_all=True\n",
    ")\n",
    "# Get cropped and prewhitened image tensor\n",
    "img = Image.open('yang-yang.jpeg')\n",
    "img_cropped = mtcnn(img)\n",
    "boxes,prob=mtcnn.detect(img)\n",
    "img_draw = img.copy()\n",
    "draw = ImageDraw.Draw(img_draw)\n",
    "\n",
    "for i, box in enumerate(boxes):\n",
    "    draw.rectangle(box.tolist())\n",
    "    extract_face(img, box, save_path='detected_face_{}.png'.format(i))\n",
    "img_draw.save('annotated_faces.png')\n",
    "    \n",
    "# Calculate embedding (unsqueeze to add batch dimension)\n",
    "im=cv2.imread('annotated_faces.png')\n",
    "img_embedding = resnet(img_cropped)\n",
    "\n",
    "\n",
    "#print(img_embedding.size())\n",
    "cos_sim = nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "verify(img_embedding)\n",
    "    \n",
    "\n",
    "cv2.imshow(\"faces\",im)\n",
    "k=cv2.waitKey(0)\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()\n",
    "#print(img_embedding.size())\n",
    "# Or, if using for VGGFace2 classification\n",
    "##resnet.classify = True\n",
    "#img_probs = resnet(img_cropped.unsqueeze(0))\n",
    "#print(img_cropped)\n",
    "#print(img_probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recogition from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1,extract_face\n",
    "from PIL import Image,ImageDraw\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "from Web.imutils.video import WebcamVideoStream\n",
    "from Web.imutils.video import FPS\n",
    "import imutils\n",
    "\n",
    "\n",
    "\n",
    "size=4\n",
    "i=1\n",
    "classifier = cv2.CascadeClassifier('/home/mj/anaconda3/share/opencv4/haarcascades/haarcascade_frontalface_default.xml')\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def cos(a,b):\n",
    "    minx = -1 \n",
    "    maxx = 1\n",
    "    return (cos_sim(a,b)- minx)/(maxx-minx)\n",
    "\n",
    "\n",
    "def verify(embedding):\n",
    "\n",
    "    for i,k in enumerate(embeddings):\n",
    "        for j,l in enumerate(embedding):\n",
    "            dist =cos(k,l)\n",
    "    \n",
    "        #print(dist)\n",
    "    # Chosen threshold is 0.7  \n",
    "            if dist > 0.85:\n",
    "                text= names[i]\n",
    "                cv2.putText(ima, text,(boxes[j][0].astype(int),boxes[j][3].astype(int)), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (0,255,0), 2)\n",
    "                print(text)\n",
    "        \n",
    "                \n",
    "device = torch.device('cpu')        \n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to('cpu')\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, prewhiten=True,\n",
    "    device=device,keep_all=True\n",
    ")\n",
    "\n",
    "vs = WebcamVideoStream(src=0).start()\n",
    "print(\"camera open\")\n",
    "while True:\n",
    "    im= vs.read()\n",
    "    im=cv2.flip(im,1) #Flip to act as a mirror\n",
    "    \n",
    "    try:\n",
    "        frame = imutils.resize(im, width=400)\n",
    "        #gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        # Resize the image to speed up detection\n",
    "\n",
    "       # detect MultiScale / faces \n",
    "        faces = classifier.detectMultiScale(frame)\n",
    "        path=\"./data/testing...\".format(i)\n",
    "        if not os.path.exists('./data/testing...'.format(i)):\n",
    "            os.makedirs('./data/testing...'.format(i))\n",
    "        img_name = \"im_{}.jpg\".format(i)    \n",
    "        cv2.imwrite(os.path.join(path,img_name),frame)\n",
    "\n",
    "\n",
    "        imgName=\"./data/testing.../im_{}.jpg\".format(i)\n",
    "        #print(\"here:\",imgName)\n",
    "    # Get cropped and prewhitened image tensor\n",
    "        img=Image.open(imgName)\n",
    "        #print(\"there:\",imgName)\n",
    "        i=i+1\n",
    "        #print(img)\n",
    "\n",
    "        img_cropped = mtcnn(img)\n",
    "        boxes,prob=mtcnn.detect(img)\n",
    "        img_draw = img.copy()\n",
    "        draw = ImageDraw.Draw(img_draw)\n",
    "        for i, box in enumerate(boxes):\n",
    "            draw.rectangle(box.tolist())\n",
    "            extract_face(img, box, save_path='detected_face_{}.png'.format(i))\n",
    "        img_draw.save('annotated_faces.png')\n",
    "        ima=cv2.imread('annotated_faces.png')\n",
    "        #print(img_cropped)\n",
    "\n",
    "    # Calculate embedding (unsqueeze to add batch dimension)\n",
    "        img_embedding = resnet(img_cropped)\n",
    "       # print(img_embedding)\n",
    "\n",
    "        cos_sim = nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "        verify(img_embedding)\n",
    "        cv2.imshow('Detecting...',ima)\n",
    "    \n",
    "    except:\n",
    "        text=\"No image found\"\n",
    "        cv2.putText(ima, text, (((box[2]-box[0])/2).astype(int),box[3].astype(int)), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Detecting...',ima)\n",
    "            \n",
    "    \n",
    "       \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "        # if Esc key is press then break out of the loop \n",
    "    if key == 27:#The Esc key\n",
    "        break         \n",
    "cv2.destroyAllWindows() \n",
    "vs.stop()\n",
    "#print(img_embedding.size())\n",
    "# Or, if using for VGGFace2 classification\n",
    "##resnet.classify = True\n",
    "#img_probs = resnet(img_cropped.unsqueeze(0))\n",
    "#print(img_cropped)\n",
    "#print(img_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
